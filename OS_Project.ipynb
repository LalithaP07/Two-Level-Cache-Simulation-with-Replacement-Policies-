{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from random import randint\n",
        "\n",
        "class CacheLine:\n",
        "    def __init__(self, size):\n",
        "        self.valid = False\n",
        "        self.tag = None\n",
        "        self.data = [0] * size\n",
        "\n",
        "class LRUCacheLine(CacheLine):\n",
        "    def __init__(self, size):\n",
        "        super().__init__(size)\n",
        "        self.access_order = 0  # To track the order of access for LRU\n",
        "\n",
        "class LRUCache:\n",
        "    def __init__(self, num_lines, line_size):\n",
        "        self.num_lines = num_lines\n",
        "        self.line_size = line_size\n",
        "        self.cache = OrderedDict()  # Ordered dictionary to maintain access order\n",
        "\n",
        "    def extract_address_parts(self, address):\n",
        "        offset_bits = 2  # Just an example, you may need to adjust based on your cache line size\n",
        "        tag_bits = 32 - offset_bits  # Assuming 32-bit addresses\n",
        "\n",
        "        offset_mask = (1 << offset_bits) - 1\n",
        "        tag_mask = ((1 << tag_bits) - 1) << offset_bits\n",
        "\n",
        "        offset = address & offset_mask\n",
        "        tag = (address & tag_mask) >> offset_bits\n",
        "        return tag, offset\n",
        "\n",
        "    def read(self, address):\n",
        "        tag, _ = self.extract_address_parts(address)\n",
        "\n",
        "        if tag in self.cache:\n",
        "            # Update access order for LRU\n",
        "            self.cache.move_to_end(tag)\n",
        "            return self.cache[tag].data\n",
        "        else:\n",
        "            print(f\"Cache miss for address {hex(address)}\")\n",
        "            # Simulate fetching data from main memory\n",
        "            data = [1, 2, 3, 4]  # Replace this with actual data retrieval\n",
        "            if len(self.cache) >= self.num_lines:\n",
        "                # Remove the least recently used entry if the cache is full\n",
        "                self.cache.popitem(last=False)\n",
        "            self.cache[tag] = LRUCacheLine(self.line_size)\n",
        "            self.cache[tag].valid = True\n",
        "            self.cache[tag].tag = tag\n",
        "            self.cache[tag].data = data\n",
        "            return data\n",
        "\n",
        "class TwoLevelCache:\n",
        "    def __init__(self, l1_cache, l2_cache):\n",
        "        self.l1_cache = l1_cache\n",
        "        self.l2_cache = l2_cache\n",
        "\n",
        "    def read(self, address):\n",
        "        # First, check L1 cache\n",
        "        l1_data = self.l1_cache.read(address)\n",
        "\n",
        "        # If L1 cache miss, check L2 cache\n",
        "        if not l1_data:\n",
        "           l2_data = self.l2_cache.read(address)\n",
        "           return l2_data\n",
        "\n",
        "        return l1_data\n",
        "\n",
        "class AssociativeCache:\n",
        "    def __init__(self, num_lines, line_size):\n",
        "        self.num_lines = num_lines\n",
        "        self.line_size = line_size\n",
        "        self.cache = [CacheLine(line_size) for _ in range(num_lines)]\n",
        "\n",
        "    def extract_address_parts(self, address):\n",
        "        offset_bits = 2  # Just an example, you may need to adjust based on your cache line size\n",
        "        tag_bits = 32 - offset_bits  # Assuming 32-bit addresses\n",
        "\n",
        "        offset_mask = (1 << offset_bits) - 1\n",
        "        tag_mask = ((1 << tag_bits) - 1) << offset_bits\n",
        "\n",
        "        offset = address & offset_mask\n",
        "        tag = (address & tag_mask) >> offset_bits\n",
        "\n",
        "        return tag, offset\n",
        "\n",
        "    def read(self, address):\n",
        "        tag, _ = self.extract_address_parts(address)\n",
        "\n",
        "        for cache_line in self.cache:\n",
        "            if cache_line.valid and cache_line.tag == tag:\n",
        "                print(f\"L2 Cache hit for address {hex(address)}\")\n",
        "                return cache_line.data\n",
        "\n",
        "        print(f\"L2 Cache miss for address {hex(address)}\")\n",
        "        # Simulate fetching data from main memory\n",
        "        data = [1, 2, 3, 4]  # Replace this with actual data retrieval\n",
        "        empty_line = next((line for line in self.cache if not line.valid), None)\n",
        "\n",
        "        if empty_line:\n",
        "            empty_line.valid = True\n",
        "            empty_line.tag = tag\n",
        "            empty_line.data = data\n",
        "        else:\n",
        "            print(\"No empty L2 cache lines available. Consider implementing a replacement policy.\")\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "class TwoLevelCacheWithLRU(TwoLevelCache):\n",
        "    def __init__(self, l1_cache_size, l2_cache_size):\n",
        "        l1_cache = LRUCache(num_lines=l1_cache_size, line_size=2)\n",
        "        l2_cache = AssociativeCache(num_lines=l2_cache_size, line_size=2)\n",
        "        super().__init__(l1_cache, l2_cache)\n",
        "\n",
        "class TwoLevelCacheEvaluator:\n",
        "    def __init__(self, two_level_cache):\n",
        "        self.two_level_cache = two_level_cache\n",
        "        self.hits = 0\n",
        "        self.misses = 0\n",
        "        self.replacements = 0  # New metric for replacements\n",
        "\n",
        "    def simulate_workload(self, addresses):\n",
        "        for address in addresses:\n",
        "            random_address = address + randint(0, 10)\n",
        "            data = self.two_level_cache.read(address)\n",
        "            if data:\n",
        "              self.hits += 1\n",
        "            else:\n",
        "                self.misses += 1\n",
        "                self.replacements += 1  # Count replacements for each miss\n",
        "\n",
        "    def calculate_hit_rate(self):\n",
        "        total_accesses = self.hits + self.misses\n",
        "        return self.hits / total_accesses if total_accesses > 0 else 0.0\n",
        "\n",
        "    def calculate_miss_rate(self):\n",
        "        total_accesses = self.hits + self.misses\n",
        "        return self.misses / total_accesses if total_accesses > 0 else 0.0\n",
        "\n",
        "    def calculate_replacement_rate(self):\n",
        "        total_accesses = self.hits + self.misses\n",
        "        return self.replacements / total_accesses if total_accesses > 0 else 0.0\n",
        "\n",
        "# the workload size\n",
        "workload_size = 1000\n",
        "workload_with_misses_lru = [randint(0, 1000) for _ in range(workload_size)]\n",
        "\n",
        "# Example usage for the Two-Level Cache with LRU\n",
        "two_level_cache_lru = TwoLevelCacheWithLRU(l1_cache_size=4, l2_cache_size=8)\n",
        "cache_evaluator_lru = TwoLevelCacheEvaluator(two_level_cache_lru)\n",
        "\n",
        "cache_evaluator_lru.simulate_workload(workload_with_misses_lru)\n",
        "\n",
        "hit_rate_lru = cache_evaluator_lru.calculate_hit_rate()\n",
        "miss_rate_lru = cache_evaluator_lru.calculate_miss_rate()\n",
        "replacement_rate_lur=cache_evaluator_lru.calculate_replacement_rate()\n",
        "\n",
        "print(\"\\nTwo-Level Cache with LRU:\")\n",
        "print(f\"Hit Rate: {hit_rate_lru:.2%}\")\n",
        "print(f\"Miss Rate: {miss_rate_lru:.2%}\")\n",
        "print(f\"Replacement Rate: {replacement_rate_lur:.2%}\")"
      ],
      "metadata": {
        "id": "VmMb_6DKbHOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict, deque\n",
        "\n",
        "\n",
        "class FIFOCacheLine(CacheLine):\n",
        "    def __init__(self, size):\n",
        "        super().__init__(size)\n",
        "\n",
        "class FIFOCache:\n",
        "    def __init__(self, num_lines, line_size):\n",
        "        self.num_lines = num_lines\n",
        "        self.line_size = line_size\n",
        "        self.cache = deque(maxlen=num_lines)  # Use deque for FIFO replacement policy\n",
        "        self.replacements = 0  # Counter for replacements\n",
        "\n",
        "    def extract_address_parts(self, address):\n",
        "        offset_bits = 2  # Just an example, you may need to adjust based on your cache line size\n",
        "        tag_bits = 32 - offset_bits  # Assuming 32-bit addresses\n",
        "\n",
        "        offset_mask = (1 << offset_bits) - 1\n",
        "        tag_mask = ((1 << tag_bits) - 1) << offset_bits\n",
        "\n",
        "        offset = address & offset_mask\n",
        "        tag = (address & tag_mask) >> offset_bits\n",
        "\n",
        "        return tag, offset\n",
        "\n",
        "    def read(self, address):\n",
        "        tag, _ = self.extract_address_parts(address)\n",
        "\n",
        "        for cache_line in self.cache:\n",
        "            if cache_line.valid and cache_line.tag == tag:\n",
        "                print(f\"L1 Cache hit for address {hex(address)}\")\n",
        "                return cache_line.data\n",
        "\n",
        "        print(f\"L1 Cache miss for address {hex(address)}\")\n",
        "        # Simulate fetching data from main memory\n",
        "        data = [1, 2, 3, 4]  # Replace this with actual data retrieval\n",
        "        if len(self.cache) >= self.num_lines:\n",
        "            # Remove the oldest entry if the cache is full (FIFO)\n",
        "            self.cache.popleft()\n",
        "            self.replacements += 1  # Increment replacements counter\n",
        "        new_cache_line = FIFOCacheLine(self.line_size)\n",
        "        new_cache_line.valid = True\n",
        "        new_cache_line.tag = tag\n",
        "        new_cache_line.data = data\n",
        "        self.cache.append(new_cache_line)\n",
        "        return data\n",
        "\n",
        "    def get_replacement_count(self):\n",
        "        return self.replacements\n",
        "\n",
        "\n",
        "class TwoLevelCacheWithFIFO(TwoLevelCache):\n",
        "    def __init__(self, l1_cache_size, l2_cache_size):\n",
        "        l1_cache = FIFOCache(num_lines=l1_cache_size, line_size=4)\n",
        "        l2_cache = AssociativeCache(num_lines=l2_cache_size, line_size=4)\n",
        "        super().__init__(l1_cache, l2_cache)\n",
        "\n",
        "# Example usage for the Two-Level Cache with FIFO\n",
        "workload_size = 1000\n",
        "workload_with_misses_fifo = [randint(0, 1000) for _ in range(workload_size)]\n",
        "\n",
        "two_level_cache_fifo = TwoLevelCacheWithFIFO(l1_cache_size=4, l2_cache_size=8)\n",
        "cache_evaluator_fifo = TwoLevelCacheEvaluator(two_level_cache_fifo)\n",
        "\n",
        "cache_evaluator_fifo.simulate_workload(workload_with_misses_fifo)\n",
        "\n",
        "hit_rate_fifo = cache_evaluator_fifo.calculate_hit_rate()\n",
        "miss_rate_fifo = cache_evaluator_fifo.calculate_miss_rate()\n",
        "replacement_rate_fifo = cache_evaluator_fifo.calculate_replacement_rate()\n",
        "\n",
        "print(\"\\nTwo-Level Cache with FIFO:\")\n",
        "print(f\"Hit Rate: {hit_rate_fifo:.2%}\")\n",
        "print(f\"Miss Rate: {miss_rate_fifo:.2%}\")\n",
        "print(f\"Replacement Rate: {replacement_rate_fifo:.2%}\")\n"
      ],
      "metadata": {
        "id": "J301eHRMcIPo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}